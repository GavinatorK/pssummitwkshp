{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastAI with SageMaker Bring your own Container\n",
    "\n",
    "In this notebook, we will cover how to bring our own container with either a framework or algorithm to train a model on SageMaker. \n",
    "\n",
    "We will use fastai in this case and build our container with custom training code integrated into the container. The other option is to use script mode which is easily done by changing the entrypoint.\n",
    "\n",
    "The outline of this notebook is \n",
    "\n",
    "1. Build docker a image for FastAI and serving and training code (provided).\n",
    "\n",
    "2. Log into ECR, tag and push docker image to ECR \n",
    "\n",
    "3. Use the FastAI container image in SageMaker to train our model \n",
    "\n",
    "4. Deploy model to endpoint using the container image\n",
    "\n",
    "5. Test inference using an image in couple of possible ways "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Container Image\n",
    "Let's start with building a container image locally and then push that to ECR (Elastic Container Registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/pssummitwkshp/byoc/docker\n"
     ]
    }
   ],
   "source": [
    "%cd ~/SageMaker/pssummitwkshp/byoc/docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  10.75kB\n",
      "Step 1/8 : FROM fastdotai/fastai:latest\n",
      " ---> c4c23d349f61\n",
      "Step 2/8 : LABEL maintainer=\"Raj Kadiyala\"\n",
      " ---> Using cache\n",
      " ---> c1feda98b8da\n",
      "Step 3/8 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 04ea84665d52\n",
      "Step 4/8 : RUN pip3 install --no-cache --upgrade requests\n",
      " ---> Using cache\n",
      " ---> 2f4283db96dc\n",
      "Step 5/8 : ENV PYTHONDONTWRITEBYTECODE=1     PYTHONUNBUFFERED=1     LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}:/usr/local/lib\"     PYTHONIOENCODING=UTF-8     LANG=C.UTF-8     LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> c97bce1a9957\n",
      "Step 6/8 : RUN pip3 install --no-cache --upgrade     sagemaker-training\n",
      " ---> Using cache\n",
      " ---> d569b2835df4\n",
      "Step 7/8 : COPY code/* /opt/ml/code/\n",
      " ---> Using cache\n",
      " ---> 64ef54f07f21\n",
      "Step 8/8 : ENV SAGEMAKER_PROGRAM train.py\n",
      " ---> Using cache\n",
      " ---> 4efcda38ad55\n",
      "Successfully built 4efcda38ad55\n",
      "Successfully tagged fastai:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t fastai ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                                                                TAG                 IMAGE ID            CREATED             SIZE\n",
      "fastai                                                                                                    latest              4efcda38ad55        15 hours ago        9.17GB\n",
      "650687152614.dkr.ecr.us-east-1.amazonaws.com/sagemaker-training-containers/script-mode-container-fastai   latest              4efcda38ad55        15 hours ago        9.17GB\n",
      "650687152614.dkr.ecr.us-east-1.amazonaws.com/sagemaker-training-containers/script-mode-container-fastai   <none>              385028ea5d16        20 hours ago        9.17GB\n",
      "fastdotai/fastai                                                                                          latest              c4c23d349f61        29 hours ago        9.13GB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the ecr details and tags \n",
    "Lets set a few params here like ecr name space , tag name etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "ecr_namespace = \"sagemaker-training-containers/\"\n",
    "prefix = \"script-mode-container-fastai\"\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = get_execution_role()\n",
    "account_id = role.split(\":\")[4]\n",
    "region = boto3.Session().region_name\n",
    "tag_name=account_id+'.dkr.ecr.'+region+'.amazonaws.com/'+ecr_repository_name+':latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'650687152614.dkr.ecr.us-east-1.amazonaws.com/sagemaker-training-containers/script-mode-container-fastai:latest'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we tag our image with the tag name we generated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag fastai $tag_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECR Repository and push steps\n",
    "\n",
    "All of these can be scripted out but they are laid out this way for transparency and step evolution understanding\n",
    "\n",
    "First we get a token credential to ECR. This will allow us to perform ECR operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!$(aws ecr get-login --no-include-email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create an ECR repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (RepositoryAlreadyExistsException) when calling the CreateRepository operation: The repository with name 'sagemaker-training-containers/script-mode-container-fastai' already exists in the registry with id '650687152614'\n"
     ]
    }
   ],
   "source": [
    "!aws ecr create-repository --repository-name $ecr_repository_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our ECR respoitory has been created, we can now push our docker image to it with the tag name we assigned to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [650687152614.dkr.ecr.us-east-1.amazonaws.com/sagemaker-training-containers/script-mode-container-fastai]\n",
      "\n",
      "\u001b[1B151aa860: Preparing \n",
      "\u001b[1Bd23a33d0: Preparing \n",
      "\u001b[1Ba4ebc26c: Preparing \n",
      "\u001b[1Bd277c3a5: Preparing \n",
      "\u001b[1Bb8a4997f: Preparing \n",
      "\u001b[1B570c96fa: Preparing \n",
      "\u001b[1B9a10a0ec: Preparing \n",
      "\u001b[1Bfdcbbf19: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1Bc4239216: Preparing \n",
      "\u001b[1B66e1e1d6: Preparing \n",
      "\u001b[1Be35a6476: Preparing \n",
      "\u001b[1B8fbc8492: Preparing \n",
      "\u001b[1Bfa06e06c: Preparing \n",
      "\u001b[1B62e73fa9: Preparing \n",
      "\u001b[1B491659cb: Preparing \n",
      "\u001b[1Bdc413928: Preparing \n",
      "\u001b[1Bad8f2cae: Preparing \n",
      "\u001b[1B581dbc3c: Preparing \n",
      "\u001b[3Bad8f2cae: Layer already exists \u001b[18A\u001b[2K\u001b[14A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[13A\u001b[2K\u001b[3A\u001b[2Klatest: digest: sha256:e4aab61bd7526510a3861b78a3efa015612d4c86aa00eb681b4c114b53f24370 size: 4711\n"
     ]
    }
   ],
   "source": [
    "!docker push $tag_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we get the URI of our uploaded docker image in ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650687152614.dkr.ecr.us-east-1.amazonaws.com/sagemaker-training-containers/script-mode-container-fastai:latest\n"
     ]
    }
   ],
   "source": [
    "container_image_uri = \"{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest\".format(\n",
    "    account_id, region, ecr_repository_name\n",
    ")\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call your custom container to train the model\n",
    "\n",
    "In the cell below, replace **\"your-unique-bucket-name\"** with the name of bucket you created in the data-prep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-23 11:38:37 Starting - Starting the training job...\n",
      "2021-09-23 11:39:01 Starting - Launching requested ML instancesProfilerReport-1632397117: InProgress\n",
      "......\n",
      "2021-09-23 11:40:01 Starting - Preparing the instances for training......\n",
      "2021-09-23 11:41:01 Downloading - Downloading input data...\n",
      "2021-09-23 11:41:21 Training - Downloading the training image........................\u001b[34m2021-09-23 11:45:29,103 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-23 11:45:30,534 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-23 11:45:30,543 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-09-23 11:45:30,550 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"lr\": 0.001\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"script-mode-container-fastai-2021-09-23-11-38-37-072\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/code\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"lr\":0.001}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=/opt/ml/code\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"lr\":0.001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"script-mode-container-fastai-2021-09-23-11-38-37-072\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--lr\",\"0.001\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python train.py --lr 0.001\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m['Priority', 'Roundabout', 'Signal']\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/97.8M [00:00<?, ?B/s]#015 27%|██▋       | 26.3M/97.8M [00:00<00:00, 276MB/s]#015 49%|████▉     | 48.0M/97.8M [00:00<00:00, 254MB/s]#015 73%|███████▎  | 71.3M/97.8M [00:00<00:00, 251MB/s]#015100%|█████████▉| 97.5M/97.8M [00:00<00:00, 258MB/s]#015100%|██████████| 97.8M/97.8M [00:00<00:00, 251MB/s]\u001b[0m\n",
      "\u001b[34m█#015epoch     train_loss  valid_loss  error_rate  time    \u001b[0m\n",
      "\n",
      "2021-09-23 11:46:23 Training - Training image download completed. Training in progress.\u001b[34m█#015█#0150         1.579847    None        None        10:33     \u001b[0m\n",
      "\u001b[34m█#015█#0151         1.132578    None        None        10:33     \u001b[0m\n",
      "\u001b[34m█#015█#0152         0.803730    None        None        10:32     \u001b[0m\n",
      "\u001b[34m█#015█#0153         0.584316    None        None        10:35     \u001b[0m\n",
      "\u001b[34m█#015█#0154         0.441992    None        None        10:36     \u001b[0m\n",
      "\u001b[34m2021-09-23 12:38:33,137 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-09-23 12:38:57 Uploading - Uploading generated training model\n",
      "2021-09-23 12:38:57 Completed - Training job completed\n",
      "Training seconds: 3476\n",
      "Billable seconds: 3476\n",
      "CPU times: user 6.91 s, sys: 302 ms, total: 7.21 s\n",
      "Wall time: 1h 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "import json\n",
    "\n",
    "bucket = \"your-unique-bucket-name\"\n",
    "\n",
    "# JSON encode hyperparameters\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters({\"lr\":1e-03})\n",
    "\n",
    "est = sagemaker.estimator.Estimator(\n",
    "    container_image_uri,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    #train_instance_type=\"local\",  # we use local mode\n",
    "    instance_type='ml.m5.12xlarge',\n",
    "    base_job_name=prefix,\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "train_config = sagemaker.session.TrainingInput(f's3://{bucket}/train')\n",
    "\n",
    "est.fit({\"train\": train_config})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We are going to do inference using SageMaker Script mode. We could create a new container or extend the container we created for training our FastAI model to implement serving for predictions. However, is this case we are going to tuse the SageMaker pre-built PyTorch container and install/update the necessary libraries to be able to implement predictions in FastAI. We have created a source folder named **inference** which contains two files. A requirements.txt file (our library and version dependencies) which contains fastai v2.5.2 and a serve.py code for doing predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by importing some libraries we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "from PIL import Image\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "prefix = \"script-mode-container-fastai\"\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get our SageMaker session and runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = boto3.client('sagemaker')\n",
    "client = boto3.client('sagemaker-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the SageMaker session to list all of our training jobs and filter the names by the prefix and completion status to retrieve our last completed FastAI training job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "script-mode-container-fastai-2021-09-23-11-38-37-072\n"
     ]
    }
   ],
   "source": [
    "list_jobs = sm.list_training_jobs()['TrainingJobSummaries']\n",
    "last_completed_job = [(i) for i in list_jobs if prefix in i['TrainingJobName'] and i['TrainingJobStatus'] == 'Completed']\n",
    "print(last_completed_job[0]['TrainingJobName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know the training job name, we use it to get the the S3 URI location of where the trained model artifacts have been stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifacts = sm.describe_training_job(TrainingJobName=last_completed_job[0]['TrainingJobName'])['ModelArtifacts']\n",
    "model_uri = model_artifacts['S3ModelArtifacts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/pssummitwkshp/byoc\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set up the PyTorch container with information it needs to run <br>\n",
    "**model_data** - S3 URI location of the trained model artifacts<br>\n",
    "**role** - IAM role of the SageMaker Notebook instance<br>\n",
    "**entry_point** - the folder/filename of the code that implements the prediction piece<br>\n",
    "**source_dir** - the folder which contains the prediction code and the requirements.txt file of the libraries that need to be installed<br>\n",
    "**framework_version** - PyTorch framework version<br>\n",
    "**py_version** - Python version<br><br><br>\n",
    "**NOTE we are using PyTorchModel container vs using the generic SageMaker Estimator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = PyTorchModel(model_data=model_uri, \n",
    "                             role=role, \n",
    "                             entry_point='inference/serve.py',\n",
    "                             source_dir='inference',\n",
    "                             framework_version='1.8',\n",
    "                             py_version='py3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we deploy the container. SageMaker will pull the inference code and requirements.txt to create the container environment to deploy for inference. Note that unlike what we did for training, we did not have to do a docker build and push to ECR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = pytorch_model.deploy(instance_type='ml.m5.4xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its deployed, lets test inference using a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.45 ms, sys: 286 µs, total: 5.74 ms\n",
      "Wall time: 565 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "im_name=\"../data/test/Signal/S2.png\"\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "EndpointName=predictor.endpoint_name,\n",
    "ContentType='application/x-image',\n",
    "Body=open(im_name, 'rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets decode and print out the JSON response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Prediction': 'Signal',\n",
       " 'Tensor': 'tensor(2)',\n",
       " 'Probabilities': 'tensor([0.0193, 0.0303, 0.9504])'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(response['Body'].read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
