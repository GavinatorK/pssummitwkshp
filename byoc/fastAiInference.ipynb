{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> &uarr;   Ensure Kernel is set to  &uarr;  </div><br><div style=\"text-align: right\"> \n",
    "conda_amazonei_pytorch_latest_p36  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom FastAI Model Inference using PyTorch Base Container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks you through setting up FastAI Model you just trained using BYOC for inference using endpoint. First we need to create a Predictor class to accept jpeg images as input and output JSON. The default behaviour is to accept a numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Sagemaker SDK if not already done so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please replace the **your-trained-model-uri** with the S3 URI location of your Fast AI Model from the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_loc='your-trained-model-uri'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the Image Predictor Class\n",
    "\n",
    "In the next cell, we will update the predictor class to accept json serializer and deserializer and accept application/x-image content type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import Predictor\n",
    "jpeg_serializer = sagemaker.serializers.IdentitySerializer(\"application/x-image\")\n",
    "json_deserializer = sagemaker.deserializers.JSONDeserializer()\n",
    "\n",
    "\n",
    "class ImagePredictor(Predictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(ImagePredictor, self).__init__(\n",
    "            endpoint_name,\n",
    "            sagemaker_session=sagemaker_session,\n",
    "            serializer=jpeg_serializer,\n",
    "            deserializer=json_deserializer,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ineference Script\n",
    "Create an Inference Script along with any libraries we need installed inside requirements.txt and save them in the inf_src folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat inf_src/serve.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat inf_src/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the model\n",
    "Using the model and ImagePredictor class from above, prepare the model for deployment as an endpoint and provide a serving script that can upack the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "model=PyTorchModel(model_data=s3_model_loc, \n",
    "                   name=name_from_base(\"fastai-custom-cont-mod\"),\n",
    "                   role=role, \n",
    "                   framework_version='1.8.0',\n",
    "                   py_version='py3',\n",
    "                   entry_point='inf_src/serve.py',\n",
    "                   source_dir= 'inf_src',\n",
    "                   predictor_cls=ImagePredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model \n",
    "\n",
    "Deploy the model to the end point using ml.m4.xlarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Your endpoint name is \\n{predictor.endpoint_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Predictor to make inference \n",
    "\n",
    "**NOTE** Replace **your-endpoint-name** with your endpoint name in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.predictor import json_serializer\n",
    "\n",
    "#copy the endpoint name and update from sagemaker console --> inference-endpoints\n",
    "endpoint_name='your-endpoint-name'\n",
    "\n",
    "predictor=Predictor(endpoint_name=endpoint_name, \n",
    "                    sagemaker_session=sagemaker_session,serializer=jpeg_serializer)\n",
    "\n",
    "with open('../data/test/Roundabout/R1.png', 'rb') as f:\n",
    "    img_byte=f.read()\n",
    "    print(predictor.predict(img_byte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Boto3 Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client=boto3.client('sagemaker-runtime')\n",
    "im_name=\"../data/test/Roundabout/R2.png\"\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "EndpointName=endpoint_name,\n",
    "ContentType='application/x-image',\n",
    "Body=open(im_name, 'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.loads(response['Body'].read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p36",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
