{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> &uarr;   Ensure Kernel is set to  &uarr;  </div><br><div style=\"text-align: right\"> \n",
    "conda_mxnet_latest_p37  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Image Classification Built-In Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "The Amazon SageMaker image classification algorithm is a supervised learning algorithm that supports multi-label classification. It takes an image as input and outputs one or more labels assigned to that image. It uses a convolutional neural network (ResNet) that can be trained from scratch or trained using transfer learning when a large number of training images are not available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outline of this notebook is \n",
    "\n",
    "1. Prepare images into RecordIO format\n",
    "\n",
    "2. Train the SageMaker Image Classification built-in algorithm \n",
    "\n",
    "3. Create and deploy the model to an endpoint for doing inference \n",
    "\n",
    "4. Test realtime inference with the endpoint\n",
    "\n",
    "5. Do batch inference using SageMaker Batch Transform\n",
    "\n",
    "Lets start by importing some base libraries and some initial variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, replace **your-unique-bucket-name** with the name of bucket you created in the data-prep notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import boto3\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "bucket = 'your-unique-bucket-name'\n",
    "\n",
    "training_image = sagemaker.image_uris.retrieve(region=boto3.Session().region_name, framework='image-classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find mxnet  so we can use some of the tools to create RecordIO format datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imrec = ! find $CONDA_PREFIX -name im2rec.py | grep -v gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now store the location of the MXNet tool im2rec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imrec_loc = imrec[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Lets first list out the folders in our data folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -1 ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a folder to store our RecordIO files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir recordio_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build our train and validation datasets in recordio format\n",
    "First we generate list files using im2rec.py from mxnet <br>\n",
    "The output will show the class label and its assigned number (implied from the folder structure)<br>\n",
    "i.e.<br>\n",
    "Priority 0<br>\n",
    "Roundabout 1<br>\n",
    "Signal 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python {imrec_loc} recordio_dataset/train ../data/train --recursive --list --num-thread 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python {imrec_loc} recordio_dataset/validation ../data/val --recursive --list --num-thread 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have generated the list files, we will use them to generate the respective training and validation recordio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python {imrec_loc} recordio_dataset/train.lst ../data/train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python {imrec_loc} recordio_dataset/validation.lst ../data/val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the train and validation datasets in recordio format, we will now copy them to our S3 bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_key = \"recordio_dataset/train\"\n",
    "s3_validation_key = \"recordio_dataset/validation\"\n",
    "\n",
    "s3_train = 's3://{}/{}/'.format(bucket, s3_train_key)\n",
    "s3_validation = 's3://{}/{}/'.format(bucket, s3_validation_key)\n",
    "\n",
    "s3_train_lst = 's3://{}/{}/'.format(bucket, \"recordio_dataset/lst/train.lst\")\n",
    "s3_validation_lst = 's3://{}/{}/'.format(bucket, \"recordio_dataset/lst/validation.lst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 cp recordio_dataset/train.rec {s3_train}\n",
    "! aws s3 cp recordio_dataset/train.idx {s3_train}\n",
    "\n",
    "! aws s3 cp recordio_dataset/validation.rec {s3_validation}\n",
    "! aws s3 cp recordio_dataset/validation.idx {s3_validation}\n",
    "\n",
    "! aws s3 cp recordio_dataset/train.lst {s3_train_lst}\n",
    "! aws s3 cp recordio_dataset/validation.lst {s3_validation_lst}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training parameters\n",
    "There are two kinds of parameters that need to be set for training. The first one are the parameters for the training job. These include:\n",
    "\n",
    "* **Training instance count**: This is the number of instances on which to run the training. When the number of instances is greater than one, then the image classification algorithm will run in distributed settings. \n",
    "* **Training instance type**: This indicates the type of machine on which to run the training. Typically, we use GPU instances for these training \n",
    "* **Output path**: This the s3 folder in which the training output is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name_prefix = 'traffic-image-classification'\n",
    "job_name = job_name_prefix + '-' + time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, job_name_prefix)\n",
    "sm_ic_estimator = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    volume_size=50,\n",
    "    max_run=360000,\n",
    "    input_mode=\"File\",\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm parameters\n",
    "\n",
    "Apart from the above set of parameters, there are hyperparameters that are specific to the algorithm. These are:\n",
    "\n",
    "* **num_layers**: The number of layers (depth) for the network. We use 18 in this samples but other values such as 50, 152 can be used.\n",
    "* **use_pretrained_model**: Set to 1 to use pretrained model for transfer learning.\n",
    "* **image_shape**: The input image dimensions,'num_channels, height, width', for the network. It should be no larger than the actual image size. The number of channels should be same as the actual image.\n",
    "* **num_classes**: This is the number of output classes for the dataset. We use 3 classes so we set this value to 3\n",
    "* **mini_batch_size**: The number of training samples used for each mini batch. In distributed training, the number of training samples used per batch will be N * mini_batch_size where N is the number of hosts on which training is run\n",
    "* **resize**: Resize the image before using it for training. The images are resized so that the shortest side is of this parameter. If the parameter is not set, then the training data is used as such without resizing.\n",
    "* **epochs**: Number of training epochs\n",
    "* **learning_rate**: Learning rate for training\n",
    "* **num_training_samples**: This is the total number of training samples. It is set to 1334 for this dataset\n",
    "\n",
    "You can find a detailed description of all the algorithm parameters at https://docs.aws.amazon.com/sagemaker/latest/dg/IC-Hyperparameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_ic_estimator.set_hyperparameters(\n",
    "    num_layers=18,\n",
    "    use_pretrained_model=1,\n",
    "    image_shape=\"3,640,640\",\n",
    "    num_classes=3,\n",
    "    mini_batch_size=64,\n",
    "    epochs=50,\n",
    "    learning_rate=0.01,\n",
    "    num_training_samples=1334,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data specification\n",
    "Set the data type and channels used for training. In this training, we use application/x-recordio content type that require the dataset to be is recordio format and lst file for data input. In addition, Sagemaker image classification algorithm supports application/x-image format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"application/x-recordio\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"application/x-recordio\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "\n",
    "train_data_lst = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_lst,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "\n",
    "validation_data_lst = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_lst,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    ")\n",
    "\n",
    "data_channels = {\n",
    "    \"train\": train_data,\n",
    "    \"validation\": validation_data,\n",
    "    \"train_lst\": train_data_lst,\n",
    "    \"validation_lst\": validation_data_lst,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can call the fit method with the input channels on the estimator to start the training<br>\n",
    "**NOTE** This cell takes **16 mins** to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sm_ic_estimator.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NOTE:** <br>\n",
    "If at this point your kernel disconnects from the server (you can tell because the kernel in the top right hand corner will say **No Kernel**),<br>you can reattach to the training job (so you dont to start the training job again).<br>Follow the steps below\n",
    "1. Scoll your notebook to the top and set the kernel to the recommended kernel specified in the top right hand corner of the notebook\n",
    "2. Go to your SageMaker console, Go to Training Jobs and copy the name of the training job you were disconnected from\n",
    "3. Scoll to the bottom of this notebook, paste your training job name to replace the **your-training-job-name** in the cell\n",
    "4. Replace **your-unique-bucket-name** with the name of bucket you created in the data-prep notebook\n",
    "5. Run the edited cell\n",
    "6. Return to this cell and continue executing the rest of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "***\n",
    "\n",
    "A trained model does nothing on its own. We now want to use the model to perform inference. For this example, that means predicting the class of the image.<br>Normally you can deploy the created model by using the deploy method in the estimator as shown in the commented section.<br>\n",
    "Since we are going to use a pretrained model we are going to create a sagemaker model using the training container, location of the model URI and serializer.<br>\n",
    "We will then deploy endpoint using the created model. \n",
    "<br>\n",
    "**NOTE** This cell takes **5 mins** to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from datetime import datetime\n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "from sagemaker.model import Model\n",
    "\n",
    "model_data = 's3://ml-materials/sm_image_class/model.tar.gz'\n",
    "# model_data is set to the pretrained model.\n",
    "# uncomment the following line the get the model URI from the training job\n",
    "#model_data = sm_ic_estimator.model_data\n",
    "\n",
    "endpoint_name = f\"sm-image-classification-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "\n",
    "sm_client = boto3.Session().client(service_name='sagemaker-runtime') \n",
    "\n",
    "sm_model = Model(image_uri=training_image, \n",
    "              model_data=model_data, \n",
    "              role=role)\n",
    "\n",
    "ic_classifier = sm_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the endpoint name and use boto3 to call the endpoint with our test image<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import json\n",
    "\n",
    "im_name=\"../data/test/Roundabout/R2.png\"\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/x-image',\n",
    "    Body=open(im_name, 'rb').read())\n",
    "\n",
    "json.loads(response['Body'].read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "You can use the following command to delete the endpoint. The endpoint that is created above is persistent and would consume resources till it is deleted.<br>It is good to delete the endpoint when it is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client('sagemaker')\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Inference\n",
    "We are going to use SageMaker Batch Transform to run batch inference on the Test dataset provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by creating a model in SageMaker. In the request, you name the model and describe a primary container.<br>For the primary container, you specify the Docker image that contains inference code, artifacts (from prior training).<br>You can optionally add a custom environment map that the inference code uses when you deploy the model for predictions.<br>\n",
    "In our case the the docker image is provided by SageMaker, so we will provide the model name and the location of the model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from datetime import datetime\n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "from sagemaker.model import Model\n",
    "\n",
    "model_data = 's3://ml-materials/sm_image_class/model.tar.gz'\n",
    "# model_data is set to the pretrained model.\n",
    "# uncomment the following line the get the model URI from the training job\n",
    "#model_data = sm_ic_estimator.model_data\n",
    "\n",
    "model_name=\"traffic-full-image-classification-model\" + time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "\n",
    "sm_model = boto3.Session().client(service_name='sagemaker') \n",
    "\n",
    "primary_container = {\n",
    "    'Image': training_image,\n",
    "    'ModelDataUrl': model_data,\n",
    "}\n",
    "\n",
    "create_model_response = sm_model.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now populate the Transformer class and provide the instance count, instance type, the model we created and the output path for the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "batch_output_path = f's3://{bucket}/batch_output'\n",
    "\n",
    "transformer = Transformer(model_name=model_name,\n",
    "                          instance_count=1,\n",
    "                          instance_type='ml.m4.xlarge',\n",
    "                          output_path=batch_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we call the transform method with the input dataset for the batch inference\n",
    "<br>\n",
    "**NOTE** This cell takes **8 mins** to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "transformer.transform(f's3://{bucket}/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing the results of the batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws s3 sync {batch_output_path} batch_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a **batch_output** folder. Feed free to navigate and doubleclick the result **.out** files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach to a training job that has been left to run \n",
    "\n",
    "If your kernel becomes disconnected and your training has already started, you can reattach to the training job.<br>\n",
    "In the cell below, replace **your-unique-bucket-name** with the name of bucket you created in the data-prep notebook<br>\n",
    "Simply look up the training job name and replace the **your-training-job-name** and then run the cell below. <br>\n",
    "Once the training job is finished, you can continue the cells after the training cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = \"your-unique-bucket-name\"\n",
    "\n",
    "training_job_name = 'your-training-job-name'\n",
    "\n",
    "if 'your-training' not in training_job_name:\n",
    "    sm_ic_estimator = sagemaker.estimator.Estimator.attach(training_job_name=training_job_name, sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_mxnet_latest_p37",
   "language": "python",
   "name": "conda_mxnet_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
